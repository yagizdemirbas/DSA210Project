{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download NLTK resources\n",
    "download('punkt')\n",
    "download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting data to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Parse `tweets.js`\n",
    "def load_tweets(file_path):\n",
    "    with open(file_path, encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        json_data = content.split('=', 1)[1].strip().rstrip(';')\n",
    "        tweets = json.loads(json_data)\n",
    "    return tweets\n",
    "\n",
    "# Step 2: Load and Parse `like.js`\n",
    "def load_likes(file_path):\n",
    "    with open(file_path, encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        json_data = content.split('=', 1)[1].strip().rstrip(';')\n",
    "        likes = json.loads(json_data)\n",
    "    return likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "tweets = load_tweets('tweets.js')\n",
    "likes = load_likes('like.js')\n",
    "\n",
    "# Flatten tweets\n",
    "tweets_df = pd.json_normalize([item['tweet'] for item in tweets if 'tweet' in item])\n",
    "\n",
    "# Flatten the 'like' key from the likes JSON\n",
    "likes_df = pd.json_normalize([item['like'] for item in likes if 'like' in item])\n",
    "\n",
    "# Rename the columns for consistency\n",
    "likes_df.rename(columns={'tweetId': 'liked_tweet_id', 'fullText': 'liked_tweet_text'}, inplace=True)\n",
    "tweets_df.rename(columns={'created_at': 'tweet_created_at', 'full_text': 'tweet_text', 'id_str': 'tweet_id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Merge Tweets and Likes\n",
    "combined_df = tweets_df.merge(\n",
    "    likes_df, left_on='tweet_id', right_on='liked_tweet_id', how='left', suffixes=('', '_liked')\n",
    ")\n",
    "\n",
    "# Add a binary column indicating if the tweet was liked\n",
    "combined_df['liked'] = combined_df['liked_tweet_id'].notna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Clean Tweet Text\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the tweet text by removing URLs, mentions, hashtags, and special characters.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\S+', '', text)    # Remove mentions\n",
    "    text = re.sub(r'#\\S+', '', text)    # Remove hashtags\n",
    "    text = re.sub(r'[^A-Za-zğüşöçıİĞÜŞÖÇ ]', '', text)  # Remove special characters\n",
    "    return text.strip().lower()\n",
    "\n",
    "combined_df['clean_text'] = combined_df['tweet_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Tokenize and Remove Stopwords\n",
    "stop_words = set(stopwords.words('turkish'))\n",
    "\n",
    "def tokenize_and_remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "combined_df['tokens'] = combined_df['clean_text'].apply(tokenize_and_remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER1\\AppData\\Local\\Temp\\ipykernel_10924\\230844531.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  combined_df['tweet_created_at'] = pd.to_datetime(combined_df['tweet_created_at'])\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Add Time-Based Features\n",
    "combined_df['tweet_created_at'] = pd.to_datetime(combined_df['tweet_created_at'])\n",
    "combined_df['day_of_week'] = combined_df['tweet_created_at'].dt.day_name()\n",
    "combined_df['hour'] = combined_df['tweet_created_at'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Handle Missing Data\n",
    "combined_df = combined_df.dropna(subset=['clean_text', 'tweet_created_at'])\n",
    "combined_df = combined_df[combined_df['clean_text'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined preprocessed data saved to 'combined_preprocessed_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Save Preprocessed Data\n",
    "combined_df.to_csv('combined_preprocessed_data.csv', index=False, encoding='utf-8')\n",
    "print(\"Combined preprocessed data saved to 'combined_preprocessed_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   retweeted                                             source  \\\n",
      "0      False  <a href=\"http://twitter.com/download/iphone\" r...   \n",
      "1      False  <a href=\"http://twitter.com/download/iphone\" r...   \n",
      "2      False  <a href=\"http://twitter.com/download/iphone\" r...   \n",
      "3      False  <a href=\"http://twitter.com/download/iphone\" r...   \n",
      "4      False  <a href=\"http://twitter.com/download/iphone\" r...   \n",
      "\n",
      "  display_text_range favorite_count             tweet_id  truncated  \\\n",
      "0           [0, 140]              0  1871313593029083255      False   \n",
      "1            [0, 74]              0  1870850626906923460      False   \n",
      "2           [0, 139]              0  1870835688226410871      False   \n",
      "3            [0, 40]              0  1869631807110717867      False   \n",
      "4            [0, 90]              5  1868700830897189196      False   \n",
      "\n",
      "  retweet_count                   id          tweet_created_at  favorited  \\\n",
      "0             0  1871313593029083255 2024-12-23 21:55:02+00:00      False   \n",
      "1             0  1870850626906923460 2024-12-22 15:15:22+00:00      False   \n",
      "2             0  1870835688226410871 2024-12-22 14:16:01+00:00      False   \n",
      "3             0  1869631807110717867 2024-12-19 06:32:13+00:00      False   \n",
      "4             0  1868700830897189196 2024-12-16 16:52:51+00:00      False   \n",
      "\n",
      "   ... in_reply_to_user_id_str withheld_in_countries liked_tweet_id  \\\n",
      "0  ...                     NaN                   NaN            NaN   \n",
      "1  ...                     NaN                   NaN            NaN   \n",
      "2  ...                     NaN                   NaN            NaN   \n",
      "3  ...                     NaN                   NaN            NaN   \n",
      "4  ...     1630183059281551361                   NaN            NaN   \n",
      "\n",
      "  liked_tweet_text expandedUrl  liked  \\\n",
      "0              NaN         NaN  False   \n",
      "1              NaN         NaN  False   \n",
      "2              NaN         NaN  False   \n",
      "3              NaN         NaN  False   \n",
      "4              NaN         NaN  False   \n",
      "\n",
      "                                          clean_text  \\\n",
      "0  rt   ya yılbaşı ile noel aynı şey değil kinede...   \n",
      "1  rt  ege tastanin tecavuz olayini yaycaz alayin...   \n",
      "2  rt  çıkan taciz olayından sonra story atan kız...   \n",
      "3                                                 rt   \n",
      "4  sanat filmlerindeki yalnızlık ve kasveti iki k...   \n",
      "\n",
      "                                              tokens day_of_week hour  \n",
      "0  [rt, yılbaşı, noel, aynı, değil, kineden, böyl...      Monday   21  \n",
      "1  [rt, ege, tastanin, tecavuz, olayini, yaycaz, ...      Sunday   15  \n",
      "2  [rt, çıkan, taciz, olayından, sonra, story, at...      Sunday   14  \n",
      "3                                               [rt]    Thursday    6  \n",
      "4  [sanat, filmlerindeki, yalnızlık, kasveti, iki...      Monday   16  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5319 entries, 0 to 5471\n",
      "Data columns (total 37 columns):\n",
      " #   Column                            Non-Null Count  Dtype              \n",
      "---  ------                            --------------  -----              \n",
      " 0   retweeted                         5319 non-null   bool               \n",
      " 1   source                            5319 non-null   object             \n",
      " 2   display_text_range                5319 non-null   object             \n",
      " 3   favorite_count                    5319 non-null   object             \n",
      " 4   tweet_id                          5319 non-null   object             \n",
      " 5   truncated                         5319 non-null   bool               \n",
      " 6   retweet_count                     5319 non-null   object             \n",
      " 7   id                                5319 non-null   object             \n",
      " 8   tweet_created_at                  5319 non-null   datetime64[ns, UTC]\n",
      " 9   favorited                         5319 non-null   bool               \n",
      " 10  tweet_text                        5319 non-null   object             \n",
      " 11  lang                              5319 non-null   object             \n",
      " 12  edit_info.initial.editTweetIds    5319 non-null   object             \n",
      " 13  edit_info.initial.editableUntil   5319 non-null   object             \n",
      " 14  edit_info.initial.editsRemaining  5319 non-null   object             \n",
      " 15  edit_info.initial.isEditEligible  5319 non-null   bool               \n",
      " 16  entities.hashtags                 5319 non-null   object             \n",
      " 17  entities.symbols                  5319 non-null   object             \n",
      " 18  entities.user_mentions            5319 non-null   object             \n",
      " 19  entities.urls                     5319 non-null   object             \n",
      " 20  possibly_sensitive                772 non-null    object             \n",
      " 21  entities.media                    392 non-null    object             \n",
      " 22  extended_entities.media           392 non-null    object             \n",
      " 23  in_reply_to_status_id_str         2942 non-null   object             \n",
      " 24  in_reply_to_user_id               2947 non-null   object             \n",
      " 25  in_reply_to_status_id             2942 non-null   object             \n",
      " 26  in_reply_to_screen_name           2321 non-null   object             \n",
      " 27  in_reply_to_user_id_str           2947 non-null   object             \n",
      " 28  withheld_in_countries             13 non-null     object             \n",
      " 29  liked_tweet_id                    0 non-null      object             \n",
      " 30  liked_tweet_text                  0 non-null      object             \n",
      " 31  expandedUrl                       0 non-null      object             \n",
      " 32  liked                             5319 non-null   bool               \n",
      " 33  clean_text                        5319 non-null   object             \n",
      " 34  tokens                            5319 non-null   object             \n",
      " 35  day_of_week                       5319 non-null   object             \n",
      " 36  hour                              5319 non-null   int32              \n",
      "dtypes: bool(5), datetime64[ns, UTC](1), int32(1), object(30)\n",
      "memory usage: 1.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(combined_df.head())\n",
    "print(combined_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
